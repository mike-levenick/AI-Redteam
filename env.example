# Copy this to .env and configure your preferred LLM

# For Anthropic Claude
ANTHROPIC_API_KEY=your_anthropic_key_here

# For OpenAI
OPENAI_API_KEY=your_openai_key_here

# For local Ollama (e.g., http://host.docker.internal:11434 on Mac)
OLLAMA_HOST=http://host.docker.internal:11434
